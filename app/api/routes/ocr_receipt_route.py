from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Form
from core.deps import get_current_user
from models.user import ReceiptResponseModel, GetUserDataModel
from PIL import Image
import pytesseract
import datetime
from fastapi.responses import JSONResponse
from core.ocr_pipeline import process_receipt
import os
import shutil
from tempfile import NamedTemporaryFile
from fastapi import FastAPI, UploadFile, File, HTTPException
from transformers import DonutProcessor, VisionEncoderDecoderModel
from PIL import Image
import torch
import io
from transformers import DonutProcessor

processor = DonutProcessor.from_pretrained("naver-clova-ix/donut-base", use_fast=True)

model = VisionEncoderDecoderModel.from_pretrained("naver-clova-ix/donut-base-finetuned-docvqa")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()

pytesseract.pytesseract.tesseract_cmd = '/usr/local/bin/tesseract'

ocr_receipt_router = APIRouter()

UPLOAD_DIR = "uploads"
os.makedirs(UPLOAD_DIR, exist_ok=True)

@ocr_receipt_router.post('/upload', response_model=ReceiptResponseModel, tags=["OCR"])
async def ocr_create_receipt_endpoint(file: UploadFile, current_user: GetUserDataModel = Depends(get_current_user)):
    try:
        accepted_content_types = ["image/jpeg", "image/png", "image/jpg"]
        if file.content_type not in accepted_content_types:
            raise HTTPException(status_code=400, detail="Invalid file type")
        image = Image.open(file.file)
        text = pytesseract.image_to_string(image)
        print(text)
        return ReceiptResponseModel(
            id="1",
            title="OCR Receipt",
            amount=0.0,
            category="Unknown",
            date="2024-01-01",
            user_id=current_user.id,
            updated_at=datetime.datetime.now(),
            created_at=datetime.datetime.now()
        )
    except Exception as e:
        print(f"Exception occured in ocr_receipt creation: {e}")
        raise HTTPException(status_code=500, detail="OCR processing failed")

@ocr_receipt_router.post("/ocr/parse-receipt")
async def parse_receipt(
    image: UploadFile = File(...)
):
    file_location = os.path.join(UPLOAD_DIR, image.filename)
    with open(file_location, "wb") as buffer:
        shutil.copyfileobj(image.file, buffer)

    try:
        result = process_receipt(file_location)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

    return JSONResponse(content={"result": result})

@ocr_receipt_router.post("/analyze-receipt")
async def analyze_receipt(file: UploadFile = File(...)):
    if not file.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail="Only image files are supported.")

    try:
        contents = await file.read()
        image = Image.open(io.BytesIO(contents)).convert("RGB")

        task_prompt = "<s_receipt-v2>"

        inputs = processor(image, task_prompt, return_tensors="pt").to(device)

        outputs = model.generate(**inputs, max_length=1024, num_beams=3)
        decoded_list = processor.batch_decode(outputs, skip_special_tokens=True)
        if not decoded_list:
            raise HTTPException(status_code=500, detail="No output generated by the model.")

        decoded = processor.batch_decode(outputs, skip_special_tokens=True)[0]

        return {"extracted_data": decoded}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to process image: {str(e)}")
